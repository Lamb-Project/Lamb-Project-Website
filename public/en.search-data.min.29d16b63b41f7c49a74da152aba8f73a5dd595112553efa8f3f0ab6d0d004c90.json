[{"id":0,"href":"/en/tutorial/","title":"Quick LAMB Tutorial","section":"LAMB - Learning Assistants Manager and Builder","content":" Quick LAMB Tutorial # Goal: in less than 15 minutes you will have a learning assistant that uses your own documents and will be available within your Moodle course.\n1. Registration and access # Go to https://lamp.lamp-project.org. Click Sign Up and complete the form (name, email, password, Secret Key provided by coordination). 2. Get to know the main dashboard # Upon entering you will see three key sections:\nMy Assistants – where your bots live. Knowledge Bases – your semantic bases. Open Web UI – the chat interface. 3. Create your first assistant # In My Assistants click New. Give it a name (e.g. Demo), describe its mission and choose the model (GPT-4o, Mistral, etc.). Save. 4. Quick assistant test # Click on the chat icon to converse and check that it responds.\n5. Create a knowledge base # Open Knowledge Bases ► New. Mark the base as Private and save. # 6. Document ingestion # Inside your base click Markdown Ingest (currently the most stable method). Drag PDFs, DOCX or .md files. Keep Chunk size ≈ 2000 for long texts. Tip: You can also upload .ZIP files as long as they contain .pdf, .docx, .txt or .md.\nYou can query the knowledge base directly:\n7. Connect the base to your assistant # Go back to My Assistants and create an assistant. In the template look for the RAG section and choose the newly created base. Indicate how many chunks (k = 3 is usually enough). Test your assistant in OpenWebui. 8. Debug mode (optional but useful) # Clone the assistant, change the model to Bypass and activate Simple RAG to see the complete prompt that LAMB sends to the LLM.\n9. Publish your assistant as an LTI tool # Publishing your LTI assistant will allow your students to access the assistant you have created from your course in Moodle or another LMS.\nFrom the Assistant detail view click Publish.\nThree pieces of data will be generated:\nTool URL Consumer Key Shared Secret 10. Insert the assistant in Moodle (LTI 1.1) # In your course ► Add activity ► External Tool. 2. Paste the Tool URL in Secure Tool URL. 3. Copy Consumer Key and Shared Secret. 4. Adjust Launch container ► New window. 5. Save.\n11. Student view # Students access from Moodle; they only see this bot and their chats are stored in LAMB, complying with the privacy policy.\n"},{"id":1,"href":"/en/roadmap/","title":"LAMB Project Roadmap","section":"LAMB - Learning Assistants Manager and Builder","content":" LAMB PROJECT ROADMAP # Last update 8/7/2025\nLAMB Main Project # The main lamb project implements the Learning Assistant manager and Builder. It combines the LAMB frontend (svelte ) and Backend (Fastapi) on a single app. It requires a slightly modified of open-webui forked from the main project. And it can be connected to lamb-project lamb-kb-server.\nMilestone Release 0.1 # Objective : Provide a codebase that a sysadmin can deploy. Owner @granludo\nTasks # Compile a semi-production ready codebase with a stable enough lamb + open-webui + lamb-kb-server -\u0026gt; @granludo -\u0026gt; Est Aug 15 2025 Write and test a comprehensive documentation (maybe a screencast of the install process). -\u0026gt; @granludo -\u0026gt; Est Aug 15 2025 Create a docker-compose so the three pieces of lamb 0.1 can be launched on containers. -\u0026gt; @juananpe -\u0026gt; Est ?? Multi tennant features and admin Milestone Analytics and Evals # (Big One) Owner TBD Objective Integrate the experimental developments for analitycs and LLM Evals into Lamb\nMilestone LTI Task activity # ** Owner ** @MJCasañ Objective Create a new kind of LTI frontend for lamb assitants: -\u0026gt; instructor sets up task and instructions for students -\u0026gt; students deliver document(s) (adding names of peers, roles and kind of contributions) -\u0026gt; lamb assitant makes rubric based assesment and feedback -\u0026gt; instructor gets assesment and decides actions (send to student(s), corrections, grade) -\u0026gt; grades can be sent to LMS via LTI gradebook integration\n[\u0026ndash;\u0026gt; It can be plugged into EvaluAItor agents ]\nLAMB-KB-Server # Owner Noa Objective Add all the experimental features on the lamb-kb-server branches, and setup LAMB to access it dynamically.\nDockling based multimodal pdf parsing, chunking and ingestion Dockling based document parsing and extraction (not provided as an embeddings kb, but as a set of raw md + img files) Video ingestion plugin (based on old LLMPrimer workflows) Import and Export of full kb-bases Re-building of kb-bases (change of embeddings functions, chunking strategy, adding metadata) Onthology driven domain enhanced ingestion, query and fine-tunning EvaluAItor Agents # A whole big ass project roadmap pending\nLAMB Jarvis # A whole big ass project roadmap pending\n"}]